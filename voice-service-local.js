// voice-service-local.js
// æœ¬åœ°è¯­éŸ³å¤„ç†æœåŠ¡ï¼šä½¿ç”¨å¼€æºæ¨¡å‹ï¼Œæ— éœ€APIå¯†é’¥

const fs = require('fs');
const path = require('path');
const axios = require('axios');
const { spawn } = require('child_process');
const ffmpeg = require('fluent-ffmpeg');
const ffmpegPath = require('@ffmpeg-installer/ffmpeg').path;
ffmpeg.setFfmpegPath(ffmpegPath);

// ä¸´æ—¶æ–‡ä»¶ç›®å½•
const TEMP_DIR = path.join(__dirname, 'temp');
if (!fs.existsSync(TEMP_DIR)) {
  fs.mkdirSync(TEMP_DIR);
}

// ä¸‹è½½Telegramè¯­éŸ³æ–‡ä»¶
async function downloadVoiceFile(fileUrl, fileId) {
  const filePath = path.join(TEMP_DIR, `${fileId}.oga`);
  const writer = fs.createWriteStream(filePath);
  
  const response = await axios({
    url: fileUrl,
    method: 'GET',
    responseType: 'stream'
  });
  
  response.data.pipe(writer);
  
  return new Promise((resolve, reject) => {
    writer.on('finish', () => resolve(filePath));
    writer.on('error', reject);
  });
}

// è½¬æ¢éŸ³é¢‘æ ¼å¼ï¼ˆOGAåˆ°WAVï¼Œç”¨äºWhisperï¼‰
async function convertToWav(inputPath) {
  const outputPath = inputPath.replace('.oga', '.wav');
  
  return new Promise((resolve, reject) => {
    ffmpeg(inputPath)
      .toFormat('wav')
      .audioFrequency(16000)  // Whisperéœ€è¦16kHz
      .audioChannels(1)        // å•å£°é“
      .on('end', () => {
        fs.unlinkSync(inputPath);
        resolve(outputPath);
      })
      .on('error', reject)
      .save(outputPath);
  });
}

// ä½¿ç”¨æœ¬åœ°Whisperè¿›è¡Œè¯­éŸ³è¯†åˆ«
async function speechToTextLocal(audioFilePath) {
  try {
    console.log('ğŸ¤ ä½¿ç”¨æœ¬åœ°Whisperè¯†åˆ«è¯­éŸ³...');
    
    return new Promise((resolve, reject) => {
      // ä½¿ç”¨whisper-cliå‘½ä»¤è¡Œå·¥å…·ï¼ˆæ–°ç‰ˆæœ¬ï¼‰
      const whisperProcess = spawn('/opt/homebrew/bin/whisper-cli', [
        '-m', path.join(__dirname, 'models', 'ggml-base.bin'), // æ¨¡å‹è·¯å¾„
        '-l', 'zh',  // ä¸­æ–‡
        '-f', audioFilePath,
        '--no-timestamps'
      ]);
      
      let output = '';
      let error = '';
      
      whisperProcess.stdout.on('data', (data) => {
        output += data.toString();
      });
      
      whisperProcess.stderr.on('data', (data) => {
        error += data.toString();
      });
      
      whisperProcess.on('close', (code) => {
        // æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        if (fs.existsSync(audioFilePath)) {
          fs.unlinkSync(audioFilePath);
        }
        
        if (code !== 0) {
          // å¦‚æœwhisperå‘½ä»¤ä¸å­˜åœ¨ï¼Œä½¿ç”¨å¤‡ç”¨æ–¹æ¡ˆ
          console.log('âš ï¸ Whisperæœ¬åœ°æ¨¡å‹æœªå®‰è£…ï¼Œä½¿ç”¨ç®€åŒ–è¯†åˆ«');
          resolve({
            text: '[è¯­éŸ³æ¶ˆæ¯]',
            language: 'zh'
          });
        } else {
          // è§£æè¾“å‡ºè·å–è¯†åˆ«æ–‡æœ¬
          const lines = output.split('\n');
          const text = lines.filter(l => l.trim() && !l.startsWith('['))
            .join(' ')
            .trim();
          
          resolve({
            text: text || '[æ— æ³•è¯†åˆ«]',
            language: 'zh'
          });
        }
      });
      
      whisperProcess.on('error', (err) => {
        console.log('âš ï¸ Whisperæœªå®‰è£…ï¼Œè¯·å‚è€ƒREADMEå®‰è£…');
        // æ¸…ç†æ–‡ä»¶
        if (fs.existsSync(audioFilePath)) {
          fs.unlinkSync(audioFilePath);
        }
        resolve({
          text: '[éœ€è¦å®‰è£…Whisperæœ¬åœ°æ¨¡å‹]',
          language: 'zh'
        });
      });
    });
  } catch (error) {
    console.error('æœ¬åœ°è¯­éŸ³è¯†åˆ«å¤±è´¥:', error);
    if (fs.existsSync(audioFilePath)) {
      fs.unlinkSync(audioFilePath);
    }
    throw error;
  }
}

// ä½¿ç”¨Edge-TTSè¿›è¡Œæ–‡å­—è½¬è¯­éŸ³ï¼ˆå…è´¹ï¼Œè´¨é‡å¥½ï¼‰
async function textToSpeechLocal(text, voice = 'zh-CN-XiaoxiaoNeural') {
  try {
    console.log('ğŸ”Š ä½¿ç”¨Edge-TTSç”Ÿæˆè¯­éŸ³...');
    
    const outputPath = path.join(TEMP_DIR, `tts_${Date.now()}.mp3`);
    
    return new Promise((resolve, reject) => {
      // ä½¿ç”¨gTTSä½œä¸ºä¸»è¦æ–¹æ¡ˆï¼ˆæ›´ç¨³å®šï¼‰
      const pythonScript = `from gtts import gTTS; tts = gTTS('${text.replace(/'/g, "\\'")}', lang='zh-CN'); tts.save('${outputPath}')`;
      const gtts = spawn('python3', ['-c', pythonScript]);
      
      let error = '';
      
      gtts.stderr.on('data', (data) => {
        error += data.toString();
      });
      
      gtts.on('close', (code) => {
        if (code !== 0) {
          console.error('gTTSç”Ÿæˆå¤±è´¥:', error);
          resolve(null);
        } else {
          console.log('âœ… è¯­éŸ³ç”ŸæˆæˆåŠŸï¼ˆGoogle TTSï¼‰');
          resolve(outputPath);
        }
      });
      
      gtts.on('error', (err) => {
        console.log('âš ï¸ gTTSæœªå®‰è£…ï¼Œè¯·è¿è¡Œ: pip3 install gtts');
        resolve(null);
      });
    });
  } catch (error) {
    console.error('æ–‡å­—è½¬è¯­éŸ³å¤±è´¥:', error);
    return null;
  }
}

// å¤„ç†Telegramè¯­éŸ³æ¶ˆæ¯ï¼ˆæœ¬åœ°ç‰ˆï¼‰
async function processVoiceMessageLocal(bot, fileId) {
  try {
    // 1. è·å–æ–‡ä»¶ä¿¡æ¯
    const file = await bot.getFile(fileId);
    const fileUrl = `https://api.telegram.org/file/bot${bot.token}/${file.file_path}`;
    
    // 2. ä¸‹è½½è¯­éŸ³æ–‡ä»¶
    console.log('ğŸ“¥ ä¸‹è½½è¯­éŸ³æ–‡ä»¶...');
    const ogaPath = await downloadVoiceFile(fileUrl, fileId);
    
    // 3. è½¬æ¢æ ¼å¼
    console.log('ğŸ”„ è½¬æ¢éŸ³é¢‘æ ¼å¼...');
    const wavPath = await convertToWav(ogaPath);
    
    // 4. æœ¬åœ°è¯­éŸ³è¯†åˆ«
    console.log('ğŸ¤ æœ¬åœ°è¯†åˆ«è¯­éŸ³å†…å®¹...');
    const result = await speechToTextLocal(wavPath);
    
    console.log('âœ… è¯­éŸ³è¯†åˆ«ç»“æœ:', result.text);
    return result;
  } catch (error) {
    console.error('å¤„ç†è¯­éŸ³æ¶ˆæ¯å¤±è´¥:', error);
    throw error;
  }
}

// è·å–å¯ç”¨çš„ä¸­æ–‡è¯­éŸ³åˆ—è¡¨
function getChineseVoices() {
  return [
    { name: 'zh-CN-XiaoxiaoNeural', gender: 'Female', description: 'æ™“æ™“ï¼ˆå¥³å£°ï¼Œæ¸©æŸ”ï¼‰' },
    { name: 'zh-CN-YunyangNeural', gender: 'Male', description: 'äº‘æ‰¬ï¼ˆç”·å£°ï¼Œæ ‡å‡†ï¼‰' },
    { name: 'zh-CN-YunxiNeural', gender: 'Male', description: 'äº‘å¸Œï¼ˆç”·å£°ï¼Œæ´»æ³¼ï¼‰' },
    { name: 'zh-CN-XiaohanNeural', gender: 'Female', description: 'æ™“æ¶µï¼ˆå¥³å£°ï¼Œä¸“ä¸šï¼‰' },
    { name: 'zh-CN-XiaomengNeural', gender: 'Female', description: 'æ™“æ¢¦ï¼ˆå¥³å£°ï¼Œç”œç¾ï¼‰' }
  ];
}

// æ¸…ç†ä¸´æ—¶æ–‡ä»¶
function cleanupTempFiles() {
  const files = fs.readdirSync(TEMP_DIR);
  const now = Date.now();
  
  files.forEach(file => {
    const filePath = path.join(TEMP_DIR, file);
    const stats = fs.statSync(filePath);
    const age = now - stats.mtimeMs;
    
    // åˆ é™¤è¶…è¿‡1å°æ—¶çš„æ–‡ä»¶
    if (age > 60 * 60 * 1000) {
      fs.unlinkSync(filePath);
      console.log(`ğŸ—‘ï¸ æ¸…ç†ä¸´æ—¶æ–‡ä»¶: ${file}`);
    }
  });
}

// æ¯å°æ—¶æ¸…ç†ä¸€æ¬¡
setInterval(cleanupTempFiles, 60 * 60 * 1000);

// æ£€æŸ¥ä¾èµ–æ˜¯å¦å®‰è£…
async function checkDependencies() {
  const checks = {
    whisper: false,
    edgeTTS: false,
    ffmpeg: true  // å·²é€šè¿‡npmå®‰è£…
  };
  
  // æ£€æŸ¥whisper
  try {
    const { execSync } = require('child_process');
    execSync('test -f /opt/homebrew/bin/whisper-cpp', { stdio: 'ignore' });
    checks.whisper = true;
  } catch {
    console.log('âš ï¸ Whisperæœªå®‰è£…ï¼Œè¯­éŸ³è¯†åˆ«åŠŸèƒ½å—é™');
    console.log('   å®‰è£…æ–¹æ³•ï¼š');
    console.log('   brew install whisper-cpp  # macOS');
    console.log('   æˆ–å‚è€ƒï¼šhttps://github.com/ggerganov/whisper.cpp');
  }
  
  // æ£€æŸ¥edge-ttsï¼ˆPythonæ¨¡å—ï¼‰
  try {
    const { execSync } = require('child_process');
    execSync('python3 -m edge_tts --help', { stdio: 'ignore' });
    checks.edgeTTS = true;
  } catch {
    console.log('âš ï¸ Edge-TTSæœªå®‰è£…ï¼Œè¯­éŸ³åˆæˆåŠŸèƒ½å—é™');
    console.log('   å®‰è£…æ–¹æ³•ï¼špip3 install edge-tts');
  }
  
  if (checks.whisper && checks.edgeTTS) {
    console.log('âœ… æœ¬åœ°è¯­éŸ³æœåŠ¡å°±ç»ªï¼ˆå®Œå…¨å…è´¹ï¼‰');
  }
  
  return checks;
}

module.exports = {
  processVoiceMessageLocal,
  speechToTextLocal,
  textToSpeechLocal,
  downloadVoiceFile,
  convertToWav,
  getChineseVoices,
  checkDependencies
};